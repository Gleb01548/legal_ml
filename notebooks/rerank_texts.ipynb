{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"src\" not in os.listdir():\n",
    "    os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from qdrant_client import QdrantClient, models\n",
    "from FlagEmbedding import BGEM3FlagModel, FlagLLMReranker\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f45925da9942269d57e5bc24d7d096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harddisk/projects/legal_ml/.venv/lib/python3.10/site-packages/FlagEmbedding/BGE_M3/modeling.py:335: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  colbert_state_dict = torch.load(os.path.join(model_dir, 'colbert_linear.pt'), map_location='cpu')\n",
      "/home/harddisk/projects/legal_ml/.venv/lib/python3.10/site-packages/FlagEmbedding/BGE_M3/modeling.py:336: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sparse_state_dict = torch.load(os.path.join(model_dir, 'sparse_linear.pt'), map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "model = BGEM3FlagModel(\"BAAI/bge-m3\", use_fp16=False, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/qdrant/workshop-ultimate-hybrid-search/blob/main/notebooks/02-hybrid-search.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание БД с несколькими векторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dense_vecs': array([-0.05599624,  0.02769903, -0.04615401, ..., -0.03377588,\n",
       "        -0.02925543, -0.04329142], dtype=float32),\n",
       " 'lexical_weights': defaultdict(int,\n",
       "             {'5187': 0.13252598,\n",
       "              '4042': 0.15637419,\n",
       "              '28068': 0.2146028,\n",
       "              '138417': 0.31710362,\n",
       "              '32': 0.04425759}),\n",
       " 'colbert_vecs': array([[-0.04191731,  0.02044222,  0.01853201, ...,  0.0173075 ,\n",
       "          0.06125861, -0.01522963],\n",
       "        [-0.03104483,  0.00796479,  0.0223996 , ...,  0.01070459,\n",
       "          0.04036965,  0.00780059],\n",
       "        [-0.03103829,  0.02579158,  0.03169292, ...,  0.0075931 ,\n",
       "          0.04057872, -0.00449112],\n",
       "        [-0.04662576,  0.0143568 ,  0.05201059, ...,  0.01773259,\n",
       "          0.04036565,  0.00740162],\n",
       "        [-0.0451145 ,  0.000516  ,  0.02601848, ...,  0.02121259,\n",
       "          0.07327194,  0.0132298 ],\n",
       "        [ 0.0091881 ,  0.00524948, -0.009853  , ...,  0.01237569,\n",
       "          0.03225253,  0.02549963]], dtype=float32)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = model.encode(\n",
    "    \"Как мне получить выплаты?\",\n",
    "    return_sparse=True,\n",
    "    return_dense=True,\n",
    "    return_colbert_vecs=True,\n",
    ")\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024,),\n",
       " (6, 1024),\n",
       " defaultdict(int,\n",
       "             {'5187': 0.13252598,\n",
       "              '4042': 0.15637419,\n",
       "              '28068': 0.2146028,\n",
       "              '138417': 0.31710362,\n",
       "              '32': 0.04425759}))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[\"dense_vecs\"].shape, vectors[\"colbert_vecs\"].shape, vectors[\"lexical_weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Как': 0.13655508,\n",
       " 'мне': 0.15718421,\n",
       " 'получить': 0.1956503,\n",
       " 'социальные': 0.22945362,\n",
       " 'выплаты': 0.25035983,\n",
       " '?': 0.034747005}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.convert_id_to_token(\n",
    "    [\n",
    "        {\n",
    "            \"5187\": 0.13655508,\n",
    "            \"4042\": 0.15718421,\n",
    "            \"28068\": 0.1956503,\n",
    "            \"207964\": 0.22945362,\n",
    "            \"138417\": 0.25035983,\n",
    "            \"32\": 0.034747005,\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "col_name = \"hybrid_search_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_collection(\n",
    "    collection_name=col_name,\n",
    "    vectors_config={\n",
    "        \"dence\": models.VectorParams(\n",
    "            size=vectors[\"dense_vecs\"].shape[0], distance=models.Distance.COSINE\n",
    "        ),\n",
    "        \"colbert\": models.VectorParams(\n",
    "            size=vectors[\"colbert_vecs\"].shape[1],\n",
    "            distance=models.Distance.COSINE,\n",
    "            multivector_config=models.MultiVectorConfig(\n",
    "                comparator=models.MultiVectorComparator.MAX_SIM\n",
    "            ),\n",
    "        ),\n",
    "    },\n",
    "    sparse_vectors_config={\"text-sparse\": models.SparseVectorParams()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = [\n",
    "    models.PointStruct(\n",
    "        id=3,\n",
    "        vector={\n",
    "            \"dence\": vectors[\"dense_vecs\"],  # Плотный вектор\n",
    "            \"colbert\": vectors[\"colbert_vecs\"],  # Плотный вектор\n",
    "            \"text-sparse\": models.SparseVector(\n",
    "                indices=list(vectors[\"lexical_weights\"].keys()),  # Индексы ненулевых элементов\n",
    "                values=list(vectors[\"lexical_weights\"].values()),  # Значения ненулевых элементов\n",
    "            ),\n",
    "        },\n",
    "        payload={\n",
    "            \"text\": \"Пример текста 3\",\n",
    "            \"metadata\": {\"author\": \"Автор 3\"},\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "client.upsert(\n",
    "    collection_name=col_name,\n",
    "    points=points,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [\"Как мне получить выплаты?\", \"социальные службы\"]\n",
    "embeddings_question = model.encode(\n",
    "    sent,\n",
    "    return_sparse=True,\n",
    "    return_dense=True,\n",
    "    return_colbert_vecs=True,\n",
    ")\n",
    "batch = [{\"question\": i, \"answer\": i, \"rating\": i, \"id\": index} for index, i in enumerate(sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['5187', '4042', '28068', '138417', '32'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_question[\"lexical_weights\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [\n",
    "    models.PointStruct(\n",
    "        id=record[\"id\"],\n",
    "        payload={\n",
    "            \"question\": record[\"question\"],\n",
    "            \"answer\": record[\"answer\"],\n",
    "            \"rating\": record[\"rating\"],\n",
    "        },\n",
    "        vector={\n",
    "            \"dense\": dence,\n",
    "            \"colbert\": colbert,\n",
    "            \"text-sparse\": models.SparseVector(\n",
    "                indices=list(sparce.keys()),\n",
    "                values=list(sparce.values()),\n",
    "            ),\n",
    "        },\n",
    "    )\n",
    "    for dence, sparce, colbert, record in zip(\n",
    "        embeddings_question[\"dense_vecs\"],\n",
    "        embeddings_question[\"lexical_weights\"],\n",
    "        embeddings_question[\"colbert_vecs\"],\n",
    "        batch,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(url=\"localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='911_hybrid'), CollectionDescription(name='questions'), CollectionDescription(name='questions3'), CollectionDescription(name='questions2')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant_client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = qdrant_client.query_points(\n",
    "    collection_name=\"911_hybrid\",\n",
    "    query=models.SampleQuery(sample=models.Sample.RANDOM),\n",
    "    limit=1,\n",
    "    with_vectors=True,\n",
    ").points[0]\n",
    "\n",
    "vector = point.vector\n",
    "question = point.payload[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.021554949,\n",
       "  0.032492597,\n",
       "  -0.011105452,\n",
       "  -0.012302949,\n",
       "  -0.012577534,\n",
       "  0.004362856,\n",
       "  0.007284139,\n",
       "  0.02918232,\n",
       "  0.013973343,\n",
       "  -0.023995707,\n",
       "  0.028770441,\n",
       "  0.039021626,\n",
       "  -0.0062582577,\n",
       "  0.008809613,\n",
       "  -0.034475714,\n",
       "  0.030860342,\n",
       "  -0.006529029,\n",
       "  -0.01076222,\n",
       "  -0.042194612,\n",
       "  -0.03295024,\n",
       "  -0.012813983,\n",
       "  -0.02451437,\n",
       "  -0.00216808,\n",
       "  -0.031012889,\n",
       "  -0.0017762239,\n",
       "  0.013088568,\n",
       "  -0.010579163,\n",
       "  -0.006422246,\n",
       "  0.051652554,\n",
       "  -0.045093015,\n",
       "  0.01076222,\n",
       "  -0.010098639,\n",
       "  0.009229118,\n",
       "  -0.0205939,\n",
       "  0.011982599,\n",
       "  -0.022348195,\n",
       "  -0.019922692,\n",
       "  0.015353897,\n",
       "  -0.025627965,\n",
       "  -0.0041035255,\n",
       "  0.033285845,\n",
       "  0.042591237,\n",
       "  -0.017237857,\n",
       "  0.011822424,\n",
       "  0.010998668,\n",
       "  -0.0028259407,\n",
       "  -0.048632115,\n",
       "  -0.011692759,\n",
       "  0.002292025,\n",
       "  -0.029075537,\n",
       "  -0.031180691,\n",
       "  0.0057853605,\n",
       "  0.07718899,\n",
       "  -0.0032873966,\n",
       "  -0.037038513,\n",
       "  0.01569713,\n",
       "  0.05946298,\n",
       "  -0.04176748,\n",
       "  -0.010136776,\n",
       "  -0.011456311,\n",
       "  -0.03536049,\n",
       "  -0.030433208,\n",
       "  -0.041553915,\n",
       "  0.037374116,\n",
       "  0.0011545932,\n",
       "  0.057998527,\n",
       "  -0.015727637,\n",
       "  0.007741781,\n",
       "  -0.028343309,\n",
       "  0.002265329,\n",
       "  -0.0059798583,\n",
       "  0.028495856,\n",
       "  -0.024499115,\n",
       "  -0.021905808,\n",
       "  -0.07889752,\n",
       "  0.002799245,\n",
       "  0.021585459,\n",
       "  0.02761108,\n",
       "  -0.05537471,\n",
       "  -0.011570721,\n",
       "  -0.043201428,\n",
       "  -0.032706164,\n",
       "  0.0038480083,\n",
       "  0.021173581,\n",
       "  -0.020502372,\n",
       "  -0.0025837717,\n",
       "  -0.0019354452,\n",
       "  0.024621151,\n",
       "  0.009930836,\n",
       "  0.03713004,\n",
       "  -0.07511435,\n",
       "  0.02085323,\n",
       "  0.010258813,\n",
       "  -0.064497046,\n",
       "  -0.005358228,\n",
       "  -0.055039104,\n",
       "  -0.014606414,\n",
       "  -0.015727637,\n",
       "  0.030753559,\n",
       "  -0.009518959,\n",
       "  0.013332644,\n",
       "  0.011044432,\n",
       "  0.021982081,\n",
       "  -0.045093015,\n",
       "  -0.04350652,\n",
       "  -0.013096196,\n",
       "  0.029441651,\n",
       "  0.015864931,\n",
       "  -0.009930836,\n",
       "  0.0032683283,\n",
       "  0.0105410265,\n",
       "  -0.0044086203,\n",
       "  0.009694388,\n",
       "  0.0052743265,\n",
       "  0.03844195,\n",
       "  0.007486264,\n",
       "  0.014903882,\n",
       "  -0.01923623,\n",
       "  -0.010586791,\n",
       "  -0.0150716845,\n",
       "  -0.01946505,\n",
       "  0.023507556,\n",
       "  0.040547103,\n",
       "  -0.008596047,\n",
       "  -0.03423164,\n",
       "  -0.027290732,\n",
       "  0.010952904,\n",
       "  0.035085905,\n",
       "  0.023065168,\n",
       "  0.027824648,\n",
       "  0.036062207,\n",
       "  0.019037917,\n",
       "  -0.0036134669,\n",
       "  -0.0029727677,\n",
       "  -0.011563093,\n",
       "  0.011509703,\n",
       "  0.0073375306,\n",
       "  0.017420914,\n",
       "  0.056900185,\n",
       "  0.0068036146,\n",
       "  0.03713004,\n",
       "  0.020960014,\n",
       "  0.015544581,\n",
       "  -0.022531252,\n",
       "  0.019587088,\n",
       "  -0.0066091167,\n",
       "  0.02947216,\n",
       "  -0.0035295656,\n",
       "  0.013477564,\n",
       "  -0.068707354,\n",
       "  -0.0005906445,\n",
       "  0.04539811,\n",
       "  0.05418484,\n",
       "  -0.013477564,\n",
       "  0.018458236,\n",
       "  -0.03237056,\n",
       "  0.052262742,\n",
       "  -0.011906326,\n",
       "  -0.016627667,\n",
       "  0.043323465,\n",
       "  0.03835042,\n",
       "  -0.004957791,\n",
       "  -0.028968753,\n",
       "  -0.028404327,\n",
       "  -0.03414011,\n",
       "  -0.0080163665,\n",
       "  -0.015079311,\n",
       "  0.027138185,\n",
       "  0.00411878,\n",
       "  -0.03468928,\n",
       "  0.041035254,\n",
       "  -0.0073604127,\n",
       "  0.021539694,\n",
       "  -0.002448386,\n",
       "  0.01514033,\n",
       "  0.04420824,\n",
       "  0.06382584,\n",
       "  0.029685726,\n",
       "  -0.051072873,\n",
       "  -0.023736376,\n",
       "  -0.031485785,\n",
       "  0.04015048,\n",
       "  -0.00065881416,\n",
       "  -0.01659716,\n",
       "  0.019648107,\n",
       "  0.047594793,\n",
       "  -0.016688686,\n",
       "  -0.01383605,\n",
       "  0.012913139,\n",
       "  0.020288806,\n",
       "  -0.016047988,\n",
       "  -0.025017776,\n",
       "  0.009122335,\n",
       "  0.021432912,\n",
       "  0.0043819244,\n",
       "  -0.025063539,\n",
       "  0.02436182,\n",
       "  0.014827608,\n",
       "  -0.021768516,\n",
       "  -0.039174177,\n",
       "  -0.06278852,\n",
       "  0.036031697,\n",
       "  0.0030719235,\n",
       "  -0.005522216,\n",
       "  0.00066358125,\n",
       "  0.0027820833,\n",
       "  -0.02497201,\n",
       "  -0.07700593,\n",
       "  0.038502965,\n",
       "  -0.036550358,\n",
       "  -0.008954533,\n",
       "  0.006334531,\n",
       "  0.0058578206,\n",
       "  0.014194537,\n",
       "  -0.042743783,\n",
       "  -0.005114152,\n",
       "  -0.013599602,\n",
       "  -0.03661138,\n",
       "  0.06400889,\n",
       "  0.02512456,\n",
       "  -0.01087663,\n",
       "  0.02947216,\n",
       "  -0.029700981,\n",
       "  -0.034994375,\n",
       "  0.025841532,\n",
       "  0.03028066,\n",
       "  0.0014997317,\n",
       "  0.021631222,\n",
       "  0.003319813,\n",
       "  -0.0014520606,\n",
       "  0.035513036,\n",
       "  0.019297248,\n",
       "  -0.022119375,\n",
       "  -0.033773996,\n",
       "  0.011982599,\n",
       "  -0.0076044886,\n",
       "  -0.04301837,\n",
       "  0.010121521,\n",
       "  -0.0057968018,\n",
       "  0.024758445,\n",
       "  0.037343606,\n",
       "  0.012508888,\n",
       "  0.036336794,\n",
       "  -0.024316058,\n",
       "  0.0040501337,\n",
       "  0.024758445,\n",
       "  -0.013988597,\n",
       "  0.043231938,\n",
       "  -0.02146342,\n",
       "  -0.013538582,\n",
       "  -0.02175326,\n",
       "  0.019617597,\n",
       "  0.042225122,\n",
       "  0.01972438,\n",
       "  0.026299173,\n",
       "  0.010716456,\n",
       "  -0.011227489,\n",
       "  -0.008878259,\n",
       "  0.024377076,\n",
       "  0.027031401,\n",
       "  -0.010113893,\n",
       "  0.017390404,\n",
       "  0.03542151,\n",
       "  0.02210412,\n",
       "  0.0042484454,\n",
       "  0.03536049,\n",
       "  -0.049608417,\n",
       "  -0.019526068,\n",
       "  -0.0076121157,\n",
       "  -0.015132703,\n",
       "  0.032248523,\n",
       "  0.0027897109,\n",
       "  0.044940468,\n",
       "  -0.021158326,\n",
       "  0.034414697,\n",
       "  -0.003272142,\n",
       "  -0.023568574,\n",
       "  -0.0049883,\n",
       "  0.05781547,\n",
       "  0.014003852,\n",
       "  0.0447269,\n",
       "  0.04847957,\n",
       "  0.0151555855,\n",
       "  0.0038747042,\n",
       "  0.05006606,\n",
       "  -1.1441056e-05,\n",
       "  0.026650032,\n",
       "  0.022317687,\n",
       "  0.012897884,\n",
       "  -0.044086203,\n",
       "  -0.035238452,\n",
       "  -0.025795767,\n",
       "  0.06004266,\n",
       "  -0.008664693,\n",
       "  -0.032156993,\n",
       "  0.01357672,\n",
       "  -0.024819463,\n",
       "  -0.176955,\n",
       "  -0.004904399,\n",
       "  0.0014043896,\n",
       "  -0.0003980534,\n",
       "  -0.019922692,\n",
       "  0.0043819244,\n",
       "  -0.07773816,\n",
       "  -0.0070248083,\n",
       "  0.012333458,\n",
       "  0.013058058,\n",
       "  0.065168254,\n",
       "  -0.043811616,\n",
       "  0.005655695,\n",
       "  0.061079983,\n",
       "  0.009694388,\n",
       "  -0.0016846955,\n",
       "  -0.010113893,\n",
       "  0.02239396,\n",
       "  0.011685132,\n",
       "  -0.030967124,\n",
       "  -0.028450092,\n",
       "  -0.07419906,\n",
       "  0.03034168,\n",
       "  0.0011116893,\n",
       "  -0.0091681,\n",
       "  -0.004073016,\n",
       "  0.013294507,\n",
       "  0.00700574,\n",
       "  0.023217715,\n",
       "  -0.00867232,\n",
       "  -0.014484377,\n",
       "  -0.05122542,\n",
       "  0.0016103286,\n",
       "  0.023141442,\n",
       "  0.003731691,\n",
       "  -0.027244968,\n",
       "  0.01644461,\n",
       "  -0.019098936,\n",
       "  0.018870115,\n",
       "  0.010403734,\n",
       "  -0.006895143,\n",
       "  0.014019107,\n",
       "  0.001278538,\n",
       "  0.030204387,\n",
       "  0.00064260594,\n",
       "  -0.05552726,\n",
       "  -0.0291213,\n",
       "  -0.007993484,\n",
       "  -0.007101082,\n",
       "  0.026497485,\n",
       "  -0.042865824,\n",
       "  -0.0020002779,\n",
       "  0.011784287,\n",
       "  -0.0363673,\n",
       "  -0.017329386,\n",
       "  -0.035085905,\n",
       "  0.048082944,\n",
       "  0.03240107,\n",
       "  0.00867232,\n",
       "  0.07602963,\n",
       "  -0.07456517,\n",
       "  -0.0116775045,\n",
       "  -0.020059984,\n",
       "  -0.06248342,\n",
       "  0.024529623,\n",
       "  0.0019487932,\n",
       "  0.021829534,\n",
       "  0.043323465,\n",
       "  0.038319908,\n",
       "  -0.015613227,\n",
       "  0.00823756,\n",
       "  -0.025521182,\n",
       "  0.023477046,\n",
       "  -0.0056251856,\n",
       "  0.01670394,\n",
       "  0.033499412,\n",
       "  -0.033926543,\n",
       "  -0.049059246,\n",
       "  0.0028183134,\n",
       "  -0.09976601,\n",
       "  -0.048021924,\n",
       "  0.04018099,\n",
       "  -0.029212829,\n",
       "  -0.011433428,\n",
       "  -0.016261553,\n",
       "  -0.02387367,\n",
       "  0.017176839,\n",
       "  0.005926467,\n",
       "  0.03999793,\n",
       "  0.23919433,\n",
       "  0.04121831,\n",
       "  -0.015231859,\n",
       "  -0.013004667,\n",
       "  0.022165138,\n",
       "  -0.031195946,\n",
       "  0.012142774,\n",
       "  0.021188835,\n",
       "  -0.012020736,\n",
       "  -0.015331015,\n",
       "  0.046587978,\n",
       "  0.011143588,\n",
       "  0.009640996,\n",
       "  -0.003138663,\n",
       "  -0.03847246,\n",
       "  0.060988456,\n",
       "  -0.0489067,\n",
       "  0.015048802,\n",
       "  0.073100716,\n",
       "  0.013874187,\n",
       "  0.008901142,\n",
       "  0.023858415,\n",
       "  -0.0024617338,\n",
       "  0.004130221,\n",
       "  -0.0019583274,\n",
       "  -0.035757113,\n",
       "  -0.05427637,\n",
       "  0.035238452,\n",
       "  -0.063398704,\n",
       "  0.0033999004,\n",
       "  -0.023019405,\n",
       "  -0.00057968014,\n",
       "  0.03770972,\n",
       "  0.02094476,\n",
       "  -0.014675061,\n",
       "  -0.009259628,\n",
       "  0.017771773,\n",
       "  -0.032126486,\n",
       "  -0.025673728,\n",
       "  -0.002292025,\n",
       "  0.00700574,\n",
       "  -0.02564322,\n",
       "  0.0124478685,\n",
       "  -0.05647305,\n",
       "  -0.021707496,\n",
       "  0.0033026515,\n",
       "  -0.019678617,\n",
       "  0.015079311,\n",
       "  0.016383592,\n",
       "  -0.036763925,\n",
       "  0.033835016,\n",
       "  -0.07999586,\n",
       "  -0.03414011,\n",
       "  0.009877445,\n",
       "  0.002181428,\n",
       "  -0.0021547321,\n",
       "  -0.0078066136,\n",
       "  -0.009145217,\n",
       "  -0.016383592,\n",
       "  0.056839164,\n",
       "  0.021158326,\n",
       "  0.01917521,\n",
       "  0.035299473,\n",
       "  -0.03548253,\n",
       "  0.035238452,\n",
       "  -0.01514033,\n",
       "  -0.00678836,\n",
       "  -0.0121961655,\n",
       "  0.049364343,\n",
       "  0.045306582,\n",
       "  -0.0065862346,\n",
       "  -0.003842288,\n",
       "  0.02358383,\n",
       "  -0.06394787,\n",
       "  -0.010464752,\n",
       "  0.027199203,\n",
       "  0.0043781106,\n",
       "  0.009442685,\n",
       "  -0.0040806434,\n",
       "  0.023644848,\n",
       "  -0.015353897,\n",
       "  -0.014385221,\n",
       "  -0.0060790144,\n",
       "  0.026711052,\n",
       "  0.0033140925,\n",
       "  -0.01192158,\n",
       "  0.07065996,\n",
       "  0.007646439,\n",
       "  0.06828022,\n",
       "  0.023599084,\n",
       "  -0.019785399,\n",
       "  -0.024621151,\n",
       "  -0.054917067,\n",
       "  0.029685726,\n",
       "  -0.0134318,\n",
       "  -0.049608417,\n",
       "  0.0017457145,\n",
       "  -0.01946505,\n",
       "  -0.03423164,\n",
       "  -0.014751335,\n",
       "  0.018046359,\n",
       "  0.003369391,\n",
       "  0.029716237,\n",
       "  -0.03002133,\n",
       "  0.020273551,\n",
       "  -0.008275697,\n",
       "  -0.05046268,\n",
       "  0.002921283,\n",
       "  -0.024621151,\n",
       "  -0.021921063,\n",
       "  0.027107675,\n",
       "  -0.0050722016,\n",
       "  -0.05717477,\n",
       "  -0.01470557,\n",
       "  0.0076769483,\n",
       "  0.035299473,\n",
       "  0.01659716,\n",
       "  0.005682391,\n",
       "  0.06376482,\n",
       "  0.028175507,\n",
       "  -0.007169728,\n",
       "  0.019281993,\n",
       "  -0.015552209,\n",
       "  0.034475714,\n",
       "  -0.028984008,\n",
       "  -0.020654919,\n",
       "  0.013408917,\n",
       "  0.046099827,\n",
       "  0.013759776,\n",
       "  0.033804506,\n",
       "  0.0021337569,\n",
       "  0.0031958683,\n",
       "  -0.016520884,\n",
       "  -0.014881,\n",
       "  0.021341383,\n",
       "  0.0077150855,\n",
       "  0.004313278,\n",
       "  0.0048281257,\n",
       "  -0.006384109,\n",
       "  0.023416027,\n",
       "  -0.033255335,\n",
       "  -0.0040501337,\n",
       "  -0.018870115,\n",
       "  -0.031516295,\n",
       "  -0.0006163869,\n",
       "  0.0074328724,\n",
       "  -0.02088374,\n",
       "  -0.00097344315,\n",
       "  0.001145059,\n",
       "  0.011898698,\n",
       "  -0.013294507,\n",
       "  0.059890114,\n",
       "  -0.0191447,\n",
       "  -0.029075537,\n",
       "  -0.009259628,\n",
       "  0.022409214,\n",
       "  0.001563611,\n",
       "  -0.065290295,\n",
       "  0.062056288,\n",
       "  -0.02776363,\n",
       "  0.013126705,\n",
       "  -0.0043094642,\n",
       "  0.0234923,\n",
       "  0.10019314,\n",
       "  0.010754593,\n",
       "  0.03542151,\n",
       "  0.005693832,\n",
       "  0.018153142,\n",
       "  0.019281993,\n",
       "  -0.036977492,\n",
       "  -0.016139517,\n",
       "  -0.06010368,\n",
       "  -0.0447269,\n",
       "  0.015636109,\n",
       "  -0.012859747,\n",
       "  0.02863315,\n",
       "  -0.028739933,\n",
       "  -0.024285547,\n",
       "  -0.03777074,\n",
       "  0.00088334485,\n",
       "  0.043109898,\n",
       "  -0.02416351,\n",
       "  -0.020929504,\n",
       "  -0.032584127,\n",
       "  0.021966828,\n",
       "  0.020441353,\n",
       "  -0.00552603,\n",
       "  -0.016078496,\n",
       "  0.036977492,\n",
       "  -0.0366724,\n",
       "  -0.037252076,\n",
       "  0.0762737,\n",
       "  -0.027687356,\n",
       "  -0.0065023336,\n",
       "  0.0129665295,\n",
       "  0.025155067,\n",
       "  0.024148256,\n",
       "  0.06321565,\n",
       "  -0.011669877,\n",
       "  -0.021341383,\n",
       "  -0.024895737,\n",
       "  0.012623298,\n",
       "  -0.008405362,\n",
       "  0.050310135,\n",
       "  0.018961644,\n",
       "  -0.020822722,\n",
       "  -0.0105410265,\n",
       "  0.021036288,\n",
       "  -0.011273254,\n",
       "  0.014263183,\n",
       "  0.015758147,\n",
       "  0.033285845,\n",
       "  -0.009656251,\n",
       "  -0.018153142,\n",
       "  -0.0045649814,\n",
       "  -0.025414398,\n",
       "  0.01412589,\n",
       "  0.040272515,\n",
       "  -0.005709087,\n",
       "  -0.06291055,\n",
       "  0.02680258,\n",
       "  -0.032004446,\n",
       "  0.036977492,\n",
       "  -0.003815592,\n",
       "  -0.062666476,\n",
       "  -0.022638036,\n",
       "  -0.00065881416,\n",
       "  0.018915879,\n",
       "  -0.02436182,\n",
       "  -0.024331313,\n",
       "  0.00051151053,\n",
       "  -0.0389301,\n",
       "  0.023782142,\n",
       "  0.0064832647,\n",
       "  0.008985043,\n",
       "  -0.0147208255,\n",
       "  0.008603674,\n",
       "  0.0127987275,\n",
       "  -0.07889752,\n",
       "  -0.0034551988,\n",
       "  -0.0007884794,\n",
       "  -0.02425504,\n",
       "  0.06834124,\n",
       "  0.028328054,\n",
       "  0.010342714,\n",
       "  0.053879745,\n",
       "  -0.024666917,\n",
       "  -0.0061285924,\n",
       "  0.022454979,\n",
       "  -0.0038708905,\n",
       "  0.0076769483,\n",
       "  -0.08603674,\n",
       "  -0.03243158,\n",
       "  -0.023507556,\n",
       "  0.03337737,\n",
       "  0.024224529,\n",
       "  -0.016078496,\n",
       "  -0.011135961,\n",
       "  0.0043514147,\n",
       "  0.022241412,\n",
       "  0.019998966,\n",
       "  -0.011364782,\n",
       "  -0.002265329,\n",
       "  -0.020319315,\n",
       "  0.04887619,\n",
       "  -0.09116233,\n",
       "  0.030219642,\n",
       "  -0.008458754,\n",
       "  0.0051599164,\n",
       "  -0.03288922,\n",
       "  -0.006147661,\n",
       "  -0.024224529,\n",
       "  0.032828204,\n",
       "  -0.058395147,\n",
       "  0.0087867305,\n",
       "  -0.03548253,\n",
       "  -0.016841235,\n",
       "  0.060866416,\n",
       "  -0.002129943,\n",
       "  0.0094884485,\n",
       "  -0.010502889,\n",
       "  -0.03319432,\n",
       "  0.010769847,\n",
       "  -0.0006044691,\n",
       "  -0.0062239342,\n",
       "  0.046160847,\n",
       "  -0.007962975,\n",
       "  0.0016160491,\n",
       "  -0.023187207,\n",
       "  0.01383605,\n",
       "  -0.011974972,\n",
       "  -0.0010992948,\n",
       "  0.0014110636,\n",
       "  0.03594017,\n",
       "  0.011273254,\n",
       "  0.008023994,\n",
       "  0.0038060579,\n",
       "  -0.010213049,\n",
       "  -0.0041836128,\n",
       "  0.011204607,\n",
       "  -0.018793842,\n",
       "  -0.008245188,\n",
       "  -0.023705868,\n",
       "  -0.008504518,\n",
       "  0.026650032,\n",
       "  0.0061247787,\n",
       "  0.0055450983,\n",
       "  0.012836864,\n",
       "  -0.029136555,\n",
       "  -0.004042506,\n",
       "  -0.036580868,\n",
       "  -0.079141594,\n",
       "  0.018412473,\n",
       "  -0.0056137447,\n",
       "  0.0062963944,\n",
       "  -0.018259926,\n",
       "  0.062361382,\n",
       "  0.0537272,\n",
       "  0.015064057,\n",
       "  0.0014425265,\n",
       "  0.004206495,\n",
       "  -0.01920572,\n",
       "  -0.020410843,\n",
       "  -0.0070591313,\n",
       "  -0.0038022443,\n",
       "  -0.0149877835,\n",
       "  -0.0020040916,\n",
       "  0.015430171,\n",
       "  -0.0003217797,\n",
       "  0.04112678,\n",
       "  -0.01975489,\n",
       "  0.0134318,\n",
       "  0.013858932,\n",
       "  -0.009442685,\n",
       "  -0.033529922,\n",
       "  -0.007970602,\n",
       "  0.03301126,\n",
       "  -0.020121003,\n",
       "  0.039235193,\n",
       "  -0.022927877,\n",
       "  -0.044543844,\n",
       "  -0.037465643,\n",
       "  0.015681874,\n",
       "  0.012585161,\n",
       "  0.004099712,\n",
       "  -0.06053081,\n",
       "  0.027000891,\n",
       "  0.014331829,\n",
       "  -0.030082349,\n",
       "  -0.012943648,\n",
       "  -0.063398704,\n",
       "  0.019037917,\n",
       "  -0.006071387,\n",
       "  -0.02950267,\n",
       "  0.01682598,\n",
       "  0.0051332205,\n",
       "  0.01711582,\n",
       "  -0.01737515,\n",
       "  0.059401963,\n",
       "  -0.01357672,\n",
       "  0.0031100602,\n",
       "  0.0009558049,\n",
       "  -0.022424469,\n",
       "  -0.0031310357,\n",
       "  -0.036184248,\n",
       "  0.03414011,\n",
       "  -0.027748374,\n",
       "  0.009351157,\n",
       "  -0.0170548,\n",
       "  -0.0262229,\n",
       "  0.0411878,\n",
       "  -0.020517627,\n",
       "  0.0117614055,\n",
       "  0.013058058,\n",
       "  -0.03651985,\n",
       "  0.01380554,\n",
       "  -0.0045649814,\n",
       "  -0.005125593,\n",
       "  0.011273254,\n",
       "  -0.037953794,\n",
       "  -0.069622636,\n",
       "  -0.0069866716,\n",
       "  -0.02056339,\n",
       "  0.0067502228,\n",
       "  0.021738006,\n",
       "  0.017863302,\n",
       "  0.013462309,\n",
       "  -0.0064832647,\n",
       "  0.0017933855,\n",
       "  -0.02512456,\n",
       "  -0.08127726,\n",
       "  0.06074438,\n",
       "  -0.011639368,\n",
       "  -0.03722157,\n",
       "  -0.14998461,\n",
       "  0.02599408,\n",
       "  -0.03493336,\n",
       "  0.009389293,\n",
       "  -0.054611973,\n",
       "  0.0043285326,\n",
       "  0.0087867305,\n",
       "  0.009648624,\n",
       "  0.008054503,\n",
       "  -0.016078496,\n",
       "  -0.015247114,\n",
       "  -0.023599084,\n",
       "  0.05006606,\n",
       "  -0.0076960167,\n",
       "  0.06657169,\n",
       "  0.03291973,\n",
       "  0.02416351,\n",
       "  -0.009297765,\n",
       "  -0.027199203,\n",
       "  0.014377593,\n",
       "  -0.012638553,\n",
       "  0.0014739893,\n",
       "  -0.0015683781,\n",
       "  0.021326128,\n",
       "  0.044086203,\n",
       "  -0.017176839,\n",
       "  0.02999082,\n",
       "  0.052567836,\n",
       "  -0.0057510375,\n",
       "  -0.010655437,\n",
       "  -0.014499632,\n",
       "  -0.03319432,\n",
       "  0.024331313,\n",
       "  0.046618488,\n",
       "  -0.021249855,\n",
       "  -0.0047213426,\n",
       "  0.031577315,\n",
       "  -0.010983414,\n",
       "  -0.053178027,\n",
       "  -0.052903444,\n",
       "  -0.06083591,\n",
       "  0.027855158,\n",
       "  -0.029609453,\n",
       "  0.020532882,\n",
       "  0.05250682,\n",
       "  -0.012020736,\n",
       "  -0.022409214,\n",
       "  -0.023141442,\n",
       "  -0.019327756,\n",
       "  -0.016871743,\n",
       "  -0.015620855,\n",
       "  -0.0030719235,\n",
       "  -0.06943958,\n",
       "  -0.008893514,\n",
       "  -0.03844195,\n",
       "  0.057662923,\n",
       "  -0.013874187,\n",
       "  -0.040303025,\n",
       "  0.02561271,\n",
       "  0.059157886,\n",
       "  0.018198906,\n",
       "  0.008596047,\n",
       "  0.0027477602,\n",
       "  -0.0112427445,\n",
       "  -0.03365196,\n",
       "  -0.014827608,\n",
       "  0.021982081,\n",
       "  0.014080126,\n",
       "  -0.0071773557,\n",
       "  -0.04112678,\n",
       "  -0.0447269,\n",
       "  -0.0120665,\n",
       "  0.0044848938,\n",
       "  -0.015620855,\n",
       "  0.017756518,\n",
       "  0.0005334392,\n",
       "  0.045001484,\n",
       "  -0.026299173,\n",
       "  0.027809393,\n",
       "  0.003247353,\n",
       "  -0.020807467,\n",
       "  0.0052133077,\n",
       "  -0.04362856,\n",
       "  -0.03301126,\n",
       "  0.02532287,\n",
       "  -0.0094045475,\n",
       "  0.0170548,\n",
       "  -0.011044432,\n",
       "  -0.045154035,\n",
       "  -0.009015552,\n",
       "  -0.024316058,\n",
       "  -0.030097604,\n",
       "  -0.023965199,\n",
       "  0.01337078,\n",
       "  -0.04713715,\n",
       "  0.030067096,\n",
       "  -0.021478675,\n",
       "  -0.012295322,\n",
       "  -0.018092124,\n",
       "  -0.017253112,\n",
       "  -0.01459116,\n",
       "  -0.062666476,\n",
       "  0.027580572,\n",
       "  -0.005232376,\n",
       "  -0.07352785,\n",
       "  -0.027748374,\n",
       "  0.037496153,\n",
       "  0.033285845,\n",
       "  -0.00899267,\n",
       "  0.026131371,\n",
       "  0.038563985,\n",
       "  -0.027946686,\n",
       "  -0.053300064,\n",
       "  -0.03471979,\n",
       "  -0.04002844,\n",
       "  0.020136258,\n",
       "  -0.021387147,\n",
       "  0.018519256,\n",
       "  0.034475714,\n",
       "  0.043262444,\n",
       "  0.032279033,\n",
       "  -0.05647305,\n",
       "  -0.009198609,\n",
       "  -0.024148256,\n",
       "  0.062025778,\n",
       "  -0.034567244,\n",
       "  0.024209274,\n",
       "  0.0056137447,\n",
       "  0.04365907,\n",
       "  0.016627667,\n",
       "  0.04646594,\n",
       "  -0.03999793,\n",
       "  0.0023339754,\n",
       "  0.032034956,\n",
       "  0.010777474,\n",
       "  0.003174893,\n",
       "  -0.030723048,\n",
       "  0.025490671,\n",
       "  -0.050615232,\n",
       "  -0.040547103,\n",
       "  0.009839308,\n",
       "  -0.015147958,\n",
       "  0.025261851,\n",
       "  -0.00899267,\n",
       "  -0.030829832,\n",
       "  -0.0038861453,\n",
       "  0.0389301,\n",
       "  -0.011616485,\n",
       "  -0.03089085,\n",
       "  0.00198693,\n",
       "  0.00567095,\n",
       "  -0.011471565,\n",
       "  0.05201867,\n",
       "  0.039601307,\n",
       "  -0.0012442148,\n",
       "  0.020227786,\n",
       "  -0.007284139,\n",
       "  -0.0399064,\n",
       "  0.007501519,\n",
       "  0.0035066835,\n",
       "  0.003962419,\n",
       "  -0.022851601,\n",
       "  -0.0033274405,\n",
       "  -0.058395147,\n",
       "  0.005930281,\n",
       "  0.015864931,\n",
       "  -0.015681874,\n",
       "  -0.011578348,\n",
       "  0.010266441,\n",
       "  -0.011563093,\n",
       "  -0.029777255,\n",
       "  0.0072421883,\n",
       "  -0.013180097,\n",
       "  0.06001215,\n",
       "  -0.025887296,\n",
       "  -0.015010665,\n",
       "  -0.03337737,\n",
       "  -0.009206236,\n",
       "  0.06376482,\n",
       "  -0.009152845,\n",
       "  0.04713715,\n",
       "  0.030860342,\n",
       "  0.009656251,\n",
       "  -0.005342973,\n",
       "  0.059676547,\n",
       "  0.0130656855,\n",
       "  -0.00061400334,\n",
       "  0.015269996,\n",
       "  -0.0130656855,\n",
       "  -0.018061614,\n",
       "  0.030799322,\n",
       "  0.014209791,\n",
       "  0.025963569,\n",
       "  0.024133,\n",
       "  0.020960014,\n",
       "  -0.0008046876,\n",
       "  -0.015636109,\n",
       "  0.01131139,\n",
       "  0.009648624,\n",
       "  0.009618115,\n",
       "  0.040882707,\n",
       "  0.02822127,\n",
       "  -0.0038766111,\n",
       "  -0.01746668,\n",
       "  -0.0058082426,\n",
       "  0.058059543,\n",
       "  0.056198467,\n",
       "  0.014598787,\n",
       "  -0.01792432,\n",
       "  -0.039845385,\n",
       "  -0.035818134,\n",
       "  0.011868188,\n",
       "  -0.03005184,\n",
       "  0.0572663,\n",
       "  0.008229933,\n",
       "  -0.032065466,\n",
       "  0.07188034,\n",
       "  0.00088668184,\n",
       "  0.0079324655,\n",
       "  -0.03188241,\n",
       "  ...],\n",
       " SparseVector(indices=[29, 49, 61, 89, 103, 255, 407, 440, 591, 1739, 2718, 2732, 2743, 3150, 3410, 3806, 5187, 5509, 7193, 9296, 12504, 25360, 25734, 43892, 46235, 54344, 57328, 59585, 73951, 75420, 76719, 117552, 129001, 197287, 222124, 232737], values=[0.043548584, 0.030700684, 0.050628662, 0.031280518, 0.11743164, 0.09277344, 0.037506104, 0.024612427, 0.03149414, 0.11553955, 0.124816895, 0.04446411, 0.105773926, 0.09350586, 0.012870789, 0.1697998, 0.028945923, 0.035949707, 0.07208252, 0.10821533, 0.08239746, 0.15002441, 0.16296387, 0.097839355, 0.26367188, 0.0501709, 0.24291992, 0.03945923, 0.07965088, 0.17590332, 0.015686035, 0.16552734, 0.13366699, 0.118896484, 0.15075684, 0.11450195]),\n",
       " 'Дочери пришло извещение на заказное письмо с извещением о налоге, но она сейчас проживает в другом городе. Как правильно оформить доверенность на его получение и кто может его заверить, кроме нотариуса. \\nСпасибо.')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector[\"dense\"], vector[\"text-sparse\"], question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_texts(text: list):\n",
    "    st = \"\"\n",
    "    for index, text in enumerate(text):\n",
    "        st += f\"Документ {index+1}\"\n",
    "        st += \"\\n\\n\\n\"\n",
    "        st += text\n",
    "        st += \"\\n\\n\\n\"\n",
    "    return st\n",
    "\n",
    "\n",
    "def search_data(collection_name, point, reranker=None, n=10):\n",
    "    vector = point.vector\n",
    "    question = point.payload[\"question\"]\n",
    "\n",
    "    # запрос для разряженного вектора\n",
    "    sparse = models.Prefetch(\n",
    "        query=models.SparseVector(\n",
    "            indices=vector[\"text-sparse\"].indices,\n",
    "            values=vector[\"text-sparse\"].values,\n",
    "        ),\n",
    "        using=\"text-sparse\",\n",
    "        limit=100,\n",
    "    )\n",
    "\n",
    "    # запрос для разряженного вектора\n",
    "    sparse_1000 = models.Prefetch(\n",
    "        query=models.SparseVector(\n",
    "            indices=vector[\"text-sparse\"].indices,\n",
    "            values=vector[\"text-sparse\"].values,\n",
    "        ),\n",
    "        using=\"text-sparse\",\n",
    "        limit=1000,\n",
    "    )\n",
    "\n",
    "    # Запрос для плотного вектора\n",
    "    dense = models.Prefetch(query=vector[\"dense\"], using=\"dense\", limit=100)\n",
    "\n",
    "    # Запрос для плотного вектора 1000\n",
    "    dense_1000 = models.Prefetch(query=vector[\"dense\"], using=\"dense\", limit=1000)\n",
    "\n",
    "    # Запрашиваем 1000 по плотным векторам из них 100 по разряженным\n",
    "    dence_sparse = models.Prefetch(\n",
    "        prefetch=[dense_1000],\n",
    "        query=models.SparseVector(\n",
    "            indices=vector[\"text-sparse\"].indices,\n",
    "            values=vector[\"text-sparse\"].values,\n",
    "        ),\n",
    "        using=\"text-sparse\",\n",
    "        limit=100,\n",
    "    )\n",
    "\n",
    "    # Запрашиваем 1000 по разряженным векторам из них 100 по плотным\n",
    "    sparce_dense = models.Prefetch(\n",
    "        prefetch=[sparse_1000], query=vector[\"dense\"], using=\"dense\", limit=100\n",
    "    )\n",
    "\n",
    "    ## Запрашиваем данные\n",
    "\n",
    "    record = {}\n",
    "    record[\"question\"] = question\n",
    "\n",
    "    if reranker:\n",
    "        record[\"model_rerank_type\"] = reranker.model_name_or_path\n",
    "\n",
    "    for name_search_type, search_type in [\n",
    "        (\"dense\", [dense]),\n",
    "        (\"sparse\", [sparse]),\n",
    "        (\"sparse+dense\", [sparse, dense]),\n",
    "        (\"sparce_dense\", [sparce_dense]),\n",
    "        (\"dence_sparse\", [dence_sparse]),\n",
    "    ]:\n",
    "        point = qdrant_client.query_points(\n",
    "            collection_name=collection_name,\n",
    "            prefetch=search_type,\n",
    "            limit=100,\n",
    "            query=models.FusionQuery(\n",
    "                fusion=models.Fusion.RRF,\n",
    "            ),\n",
    "            timeout=1000,\n",
    "        ).points\n",
    "\n",
    "        texts = [i.payload[\"question\"] for i in point[1:]]\n",
    "        record[name_search_type] = convert_texts(texts[:n])\n",
    "        record[f\"{name_search_type}_len\"] = sum([len(i) for i in texts[:n]])\n",
    "\n",
    "        if reranker:\n",
    "            print(\"rerank_start\")\n",
    "            score = reranker.compute_score([[question, i] for i in texts])\n",
    "            print(\"reranl_stop\")\n",
    "            texts_score = sorted(\n",
    "                [(text, score) for text, score in zip(texts, score)],\n",
    "                key=lambda x: x[1],\n",
    "                reverse=True,\n",
    "            )[:n]\n",
    "            texts = [i[0] for i in texts_score]\n",
    "            record[f\"{name_search_type}_rerank\"] = texts\n",
    "            record[f\"{name_search_type}_rerank_len\"] = sum([len(i) for i in texts])\n",
    "            \n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reranker = FlagLLMReranker(\"BAAI/bge-reranker-v2-gemma\", use_fp16=True, device=\"cpu\")\n",
    "# reranker.compute_score([[\"owl1\", \"333 dfff\"], [\"owl22\", \"oop ppop op\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point(collection_name, n):\n",
    "    return qdrant_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.SampleQuery(sample=models.Sample.RANDOM),\n",
    "        limit=n,\n",
    "        with_vectors=True,\n",
    "    ).points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `XLMRobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Some weights of XLMRobertaForCausalLM were not initialized from the model checkpoint at BAAI/bge-reranker-v2-m3 and are newly initialized: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rerank_start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"911_hybrid\"\n",
    "\n",
    "points = get_point(collection_name, n=200)\n",
    "reranker = FlagLLMReranker(\"BAAI/bge-reranker-v2-m3\", use_fp16=True, device=\"cpu\")\n",
    "\n",
    "records = []\n",
    "for point in tqdm(points):\n",
    "    records.append(search_data(collection_name=\"911_hybrid\", point=point, n=5, reranker=reranker))\n",
    "\n",
    "pd.DataFrame(records).to_csv(\"./data/interim/rag_results/rag_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(records).to_excel(\"./data/interim/rag_results/rag_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dense_len</th>\n",
       "      <th>sparse_len</th>\n",
       "      <th>sparse+dense_len</th>\n",
       "      <th>sparce_dense_len</th>\n",
       "      <th>dence_sparse_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1584.780000</td>\n",
       "      <td>44105.685000</td>\n",
       "      <td>28930.470000</td>\n",
       "      <td>1799.600000</td>\n",
       "      <td>3884.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1336.216425</td>\n",
       "      <td>55871.782774</td>\n",
       "      <td>38865.645246</td>\n",
       "      <td>1445.435397</td>\n",
       "      <td>5791.876304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>189.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>586.500000</td>\n",
       "      <td>3434.500000</td>\n",
       "      <td>1779.750000</td>\n",
       "      <td>643.500000</td>\n",
       "      <td>1556.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1277.000000</td>\n",
       "      <td>16603.000000</td>\n",
       "      <td>5443.500000</td>\n",
       "      <td>1444.000000</td>\n",
       "      <td>2866.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2144.000000</td>\n",
       "      <td>68814.500000</td>\n",
       "      <td>43500.500000</td>\n",
       "      <td>2452.000000</td>\n",
       "      <td>4322.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9111.000000</td>\n",
       "      <td>234500.000000</td>\n",
       "      <td>177439.000000</td>\n",
       "      <td>8457.000000</td>\n",
       "      <td>73822.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dense_len     sparse_len  sparse+dense_len  sparce_dense_len  \\\n",
       "count   200.000000     200.000000        200.000000        200.000000   \n",
       "mean   1584.780000   44105.685000      28930.470000       1799.600000   \n",
       "std    1336.216425   55871.782774      38865.645246       1445.435397   \n",
       "min     189.000000     229.000000        207.000000        191.000000   \n",
       "25%     586.500000    3434.500000       1779.750000        643.500000   \n",
       "50%    1277.000000   16603.000000       5443.500000       1444.000000   \n",
       "75%    2144.000000   68814.500000      43500.500000       2452.000000   \n",
       "max    9111.000000  234500.000000     177439.000000       8457.000000   \n",
       "\n",
       "       dence_sparse_len  \n",
       "count        200.000000  \n",
       "mean        3884.205000  \n",
       "std         5791.876304  \n",
       "min          229.000000  \n",
       "25%         1556.000000  \n",
       "50%         2866.000000  \n",
       "75%         4322.750000  \n",
       "max        73822.000000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_records = pd.DataFrame(records)\n",
    "\n",
    "df_records.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
