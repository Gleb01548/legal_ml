{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"src\" not in os.listdir():\n",
    "    os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harddisk/projects/legal_ml/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "\n",
    "MODEL_NAME = \"unsloth/Qwen2.5-7B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_from_disk(\"./data/processed/100k_rows_qwen\")\n",
    "train = dataset[\"train\"]\n",
    "valid = dataset[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "–¢—ã —é—Ä–∏—Å—Ç. –¢—ã –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–µ—à—å –ª—é–¥–µ–π –ø–æ —Ä–∞–∑–Ω—ã–º –ø—Ä–æ–±–ª–µ–º–∞–º, –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–π, —á—Ç–æ —Ç–µ–±–µ –ø–∏—à—É—Ç, –æ—Ç–≤–µ—Ç—å –Ω–∞ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –¥–∞–π –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é. –û—Ç–≤–µ—Ç –ø–∏—à–∏ —Ç–æ–ª—å–∫–æ –Ω–∞ –†–£–°–°–ö–û–ú —è–∑—ã–∫–µ!<|im_end|>\n",
      "<|im_start|>user\n",
      "–í—ã–∑–≤–∞–ª–∏ –Ω–∞ –¥–æ–º —á–µ–ª–æ–≤–µ–∫–∞ —Å–¥–µ–ª–∞—Ç—å –¥–∏–≤–∞–Ω –æ–Ω –∑–∞–±—Ä–∞–ª –µ–≥–æ —Å–¥–µ–ª–∞–ª –∑–∞–ø–ª–∞—Ç–∏–ª–∏ –¥–µ–Ω—å–≥–∏, –∞ —Ç–µ–ø–µ—Ä—å –æ–Ω —Ä–∞–∑–≤–∞–ª–∏–≤–∞–µ—Ç—Å—è –ø—Ä–æ—à–ª–æ 5 –¥–Ω–µ–π, —á—Ç–æ –¥–µ–ª–∞—Ç—å —á—Ç–æ–± –≤–µ—Ä–Ω—É—Ç—å –¥–µ–Ω—å–≥–∏ –∑–∞ –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é —É—Å–ª—É–≥—É. –ò–∑ –¥–æ–≥–æ–≤–æ—Ä–∞ —Ç–æ–ª—å–∫–æ –ª–∏—Å—Ç–æ–∫ –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ–ø–∏—Å–∞–Ω—ã –≤—Å–µ —É—Å–ª—É–≥–∏ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å –¥–∞—Ç–∞ –∏ –ø—Ä–∞–≤–∞ –æ–Ω –ø—Ä–∏–∫–ª–∞–¥—ã–≤–∞–ª –¥–ª—è —Ñ–æ—Ç–æ, —Å —ç—Ç–∏–º –º–æ–∂–Ω–æ —á—Ç–æ —Ç–æ —Å–¥–µ–ª–∞—Ç—å –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –¥–µ–Ω–µ–≥? –ö—É–¥–∞ –º–Ω–µ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è?<|im_end|>\n",
      "<|im_start|>system\n",
      "–ü–µ—Ä–µ–¥ —Ç–µ–º –∫–∞–∫ –¥–∞—Ç—å –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é –∏–∑—É—á–∏ –≤–æ–ø—Ä–æ—Å—ã –¥—Ä—É–≥–∏—Ö –ª—é–¥–µ–π –∏ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –Ω–∏—Ö –¥—Ä—É–≥–∏—Ö —é—Ä–∏—Å—Ç–æ–≤:\n",
      "–í–æ–ø—Ä–æ—Å –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞:\n",
      "    –Ø –∫—É–ø–∏–ª–∞ –¥–∏–≤–∞–Ω –∫–æ—Ç–æ—Ä—ã–π –≤ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏–∏ –≤–∑–¥—É–ª—Å—è –∏ –æ—Å–µ–ª, –ø—Ä–æ–¥–∞–≤–µ—Ü —Å–æ–≥–ª–∞—Å–∏–ª—Å—è –Ω–∞ –≤–æ–∑–≤—Ä–∞—Ç –¥–µ–Ω–µ–≥. –°–∫–æ–ª—å–∫–æ –∏ –∫–æ–≥–¥–∞ –æ–Ω–∏ –ø–µ—Ä–µ–≤–µ–¥—É—Ç –º–Ω–µ –Ω–µ —Å–∫–∞–∑–∞–ª–∏, –∞ –ø–æ–∑–≤–æ–Ω–∏–ª–∏ –∏ —Å–∫–∞–∑–∞–ª–∏ —á—Ç–æ –∑–∞–±–µ—Ä—É—Ç –¥–∏–≤–∞–Ω. –°–ø–∞—Ç—å –ø–æ–ª—É—á–∞–µ—Ç—Å—è –º–Ω–µ –±—É–¥–µ—Ç –Ω–µ –≥–¥–µ. –ü–æ–¥—Å–∫–∞–∂–∏—Ç–µ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ –Ω–∞ —á—Ç–æ —è –∏–º–µ—é –ø—Ä–∞–≤–æ?\n",
      "    –û—Ç–≤–µ—Ç —é—Ä–∏—Å—Ç–∞:\n",
      "    –í—ã –¥–æ–ª–∂–Ω—ã —Å–æ–≥–ª–∞—Å–æ–≤–∞—Ç—å –ø–∏—Å—å–º–µ–Ω–Ω–æ –≤—Å–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç—ã–µ –º–µ–∂–¥—É –ø—Ä–æ–¥–∞–≤—Ü–æ–º –∏ –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–º –¥–æ–≥–æ–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç–∏.\n",
      "    –í–æ–ø—Ä–æ—Å –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞:\n",
      "    –ü—Ä–∏–æ–±—Ä–µ–ª –¥–∏–≤–∞–Ω, –∫–æ—Ç–æ—Ä—ã–π –æ–∫–∞–∑–∞–ª—Å—è –Ω–µ–Ω–∞–¥–ª–µ–∂–∞—â–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞. –ü—Ä–æ–¥–∞–≤–µ—Ü-–ò–∑–≥–æ—Ç–æ–≤–∏—Ç–µ–ª—å 3 —Ä–∞–∑–∞ —É—Å—Ç—Ä–∞–Ω—è–ª –±—Ä–∞–∫ –∑–∞ —Å–≤–æ–π —Å—á–µ—Ç. –ù–∞ 4 –π —Ä–∞–∑ –ø–æ–ª–æ–º–∫–∏ (—Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ —à–≤–æ–≤ –Ω–∞ —Ç–∫–∞–Ω–∏) –Ω–∞–ø–∏—Å–∞–ª –ø—Ä–µ—Ç–µ–Ω–∑–∏—é, —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ–º –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–π –¥–∏–≤–∞–Ω. –ì–∞—Ä–∞–Ω—Ç–∏–π–Ω—ã–π —Å—Ä–æ–∫ –µ—â–µ –Ω–µ –ø—Ä–æ—à–µ–ª. –ó–∞–±—Ä–∞–ª–∏ –¥–∏–≤–∞–Ω –Ω–∞ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –∏ —á–µ—Ä–µ–∑ 38 –¥–Ω–µ–π –ø–æ—Å–ª–µ –ø–æ–¥–∞—á–∏ –ø—Ä–µ—Ç–µ–Ω–∑–∏–∏ –æ—Ç–≤–µ—Ç–∏–ª–∏, —á—Ç–æ –∑–∞–º–µ–Ω–∞ –¥–∏–≤–∞–Ω–∞ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞ –ø–æ –ø—Ä–∏—á–∏–Ω–µ —Å–Ω—è—Ç–∏—è –µ—ë —Å –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞. –ü—Ä–µ–¥–ª–æ–∂–∏–ª–∏ –∑–∞–±—Ä–∞—Ç—å –¥–µ–Ω—å–≥–∏ –≤ —Å—É–º–º–µ —Å –ø–µ—Ä–µ—Ä–∞—Å—á–µ—Ç–æ–º —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –¥–∏–≤–∞–Ω–∞ –Ω–∞ –¥–∞—Ç—É –ø–æ–¥–∞—á–∏ –ø—Ä–µ—Ç–µ–Ω–∑–∏–∏. –ù–æ –Ω–∞ –¥–∞—Ç—É –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –ø—Ä–µ—Ç–µ–Ω–∑–∏—é —Å—Ç–æ–∏–º–æ—Å—Ç—å –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–≥–æ –¥–∏–≤–∞–Ω–∞ –≥–æ—Ä–∞–∑–¥–æ –≤—ã—à–µ, —á–µ–º –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –≤–µ—Ä–Ω—É—Ç—å. –í –æ—Ç–≤–µ—Ç–µ –Ω–∞ –ø—Ä–µ—Ç–µ–Ω–∑–∏—é –ø—Ä–æ–¥–∞–≤–µ—Ü –ª—É–∫–∞–≤–∏—Ç, —Ç.–∫. –¥–∏–≤–∞–Ω —Ç–∞–∫–æ–π –∂–µ –µ—Å—Ç—å –≤ –ø—Ä–æ–¥–∞–∂–µ –∫–∞–∫ –≤ –º–∞–≥–∞–∑–∏–Ω–µ, —Ç–∞–∫ –∏ –Ω–∞ —Å–∞–π—Ç–µ, —Ç–∞–∫ –∂–µ –µ—Å—Ç—å –¥—Ä—É–≥–∏–µ –ø–æ—Ö–æ–∂–∏–µ –¥–∏–≤–∞–Ω—ã, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –ø–æ–º–µ–Ω—è—Ç—å –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π. –í–æ–ø—Ä–æ—Å—ã: 1. –ù–∞ –∫–∞–∫–æ–π –¥–µ–Ω—å –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–≤–æ–¥–∏—Ç—å—Å—è —Ä–∞—Å—á–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –¥–∏–≤–∞–Ω–∞? –ù–∞ –¥–∞—Ç—É –ø–æ–¥–∞—á–∏ –ø—Ä–µ—Ç–µ–Ω–∑–∏–∏, –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –Ω–µ—ë –∏–ª–∏ –∂–µ –Ω–∞ –º–æ–º–µ–Ω—Ç –≤–æ–∑–≤—Ä–∞—Ç–∞ –¥–µ–Ω–µ–≥? 2. –ú–æ–∂–Ω–æ –ª–∏ –∑–∞—Å—Ç–∞–≤–∏—Ç—å –≤—Å—ë —Ç–∞–∫–∏ –ø—Ä–æ–¥–∞–≤—Ü–∞ –∏–∑–≥–æ—Ç–æ–≤–∏—Ç—å —Ç–∞–∫–æ–π –∂–µ –¥–∏–≤–∞–Ω –∏ –∫–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º? 3. –ú–æ–∂–Ω–æ –ª–∏ –∑–∞–∫–∞–∑–∞—Ç—å –¥—Ä—É–≥–æ–π –¥–∏–≤–∞–Ω —É —ç—Ç–æ–≥–æ –∂–µ –ø—Ä–æ–¥–∞–≤—Ü–∞ —Å –¥–æ–ø–ª–∞—Ç–æ–π (–∏–ª–∏ —É–º–µ–Ω—å—à–µ–Ω–∏–µ–º) —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∏ –Ω–∞ –∫–∞–∫–æ–π –¥–µ–Ω—å —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—Ç—å —Å—Ç–æ–∏–º–æ—Å—Ç—å –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –¥–∏–≤–∞–Ω–∞? 4. –ö–∞–∫–∏–µ –Ω–µ—É—Å—Ç–æ–π–∫–∏ –∏ —à—Ç—Ä–∞—Ñ—ã –º–æ–∂–µ—Ç –Ω–∞–ª–æ–∂–∏—Ç—å –Ω–∞ –ø—Ä–æ–¥–∞–≤—Ü–∞ —Å—É–¥ –≤ –¥–∞–Ω–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏?\n",
      "    –û—Ç–≤–µ—Ç —é—Ä–∏—Å—Ç–∞:\n",
      "    –ï—Å–ª–∏ —Ç–∞–∫–æ–π –¥–∏–≤–∞–Ω –µ—Å—Ç—å –≤ –Ω–∞–ª–∏—á–∏–∏ –∑–Ω–∞—á–∏—Ç –æ–±—è–∑–∞–Ω –∑–∞–º–µ–Ω–∏—Ç—å, –ø—Ä–∏ –æ—Ç–∫–∞–∑–µ —Å –Ω–µ–≥–æ –≤–∑—ã—Å–∫–∏–≤–∞–µ—Ç—Å—è –Ω–µ—É—Å—Ç–æ–π–∫–∞ –∑–∞ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –Ω–∞—Ä—É—à–µ–Ω–∏—è —Å—Ä–æ–∫–∞ –∑–∞–º–µ–Ω—ã, –¥–ª—è —ç—Ç–æ–≥–æ –∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ –ø—Ä–µ—Ç–µ–Ω–∑–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ—Ä–º –ì–ö —Å —Ä–∞—Å—á–µ—Ç–æ–º.\n",
      "    –í–æ–ø—Ä–æ—Å –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞:\n",
      "    –ü—Ä–æ–∂–∏–ª–∏ –≤ –∫–≤–∞—Ä—Ç–∏—Ä–µ 2 –Ω–æ—á–∏ –∏ —Ä–µ—à–∏–ª–∏ —Å—ä–µ—Ö–∞—Ç—å, –∏–±–æ —Ö–æ–∑—è–π–∫–∞ –Ω–µ–∞–¥–µ–∫–≤–∞—Ç–Ω–∞—è. –ó–∞–ø–ª–∞—Ç–∏–ª–∏ –µ–π 20 + 5 —Ç –∑–∞–ª–æ–≥. –°–µ–π—á–∞—Å –æ–Ω–∞ –≥–æ–≤–æ—Ä–∏—Ç \"—è –≤–∞–º –∫—É–ø–∏–ª–∞ –¥–∏–≤–∞–Ω –∏ –Ω–µ –º–æ–≥—É –≤–µ—Ä–Ω—É—Ç—å –¥–µ–Ω—å–≥–∏, –≤–µ–¥—å —Å–∞–º–∞ –ø–æ—Ç—Ä–∞—Ç–∏–ª–∞ —Å–≤–æ–∏ –¥–µ–Ω—å–≥–∏ –Ω–∞ –Ω–µ–≥–æ \".–û—Ç–¥–∞—Å—Ç —Ç–æ–ª—å–∫–æ 5 —Ç—ã—Å—è—á. –ß—Ç–æ –º–æ–∂–Ω–æ —Å —ç—Ç–∏–º —Å–¥–µ–ª–∞—Ç—å –∏ –µ—Å—Ç—å –ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≤–µ—Ä–Ω—É—Ç—å –¥–µ–Ω—å–≥–∏? –î–æ–≥–æ–≤–æ—Ä –ø–æ–¥–ø–∏—Å—ã–≤–∞–ª–∏.\n",
      "    –û—Ç–≤–µ—Ç —é—Ä–∏—Å—Ç–∞:\n",
      "    –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ!–í–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–µ–¥—ä—è–≤–∏—Ç—å –µ–π –ø–∏—Å—å–º–µ–Ω–Ω—É—é –ø—Ä–µ—Ç–µ–Ω–∑–∏—é.–ù–∞–ø–∏—à–∏—Ç–µ —é—Ä–∏—Å—Ç—É –≤ –ª–∏—á–Ω–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏, –Ω–∞ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—É—é –ø–æ—á—Ç—É, –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ø—Ä–µ—Ç–µ–Ω–∑–∏–∏.\n",
      "    <|im_end|>\n",
      "<|im_start|>assistant\n",
      "–ü–æ–¥–∞–≤–∞–π—Ç–µ –ø–∏—Å—å–º–µ–Ω–Ω—É—é –ø—Ä–µ—Ç–µ–Ω–∑–∏—é. –í —Å–ª—É—á–∞–µ –Ω–µ–∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å –≤ —Å—É–¥.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train[\"prompt_context\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2024.12.9: Fast Qwen2 patching. Transformers: 4.47.1.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090. Max memory: 23.542 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.12.9 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = MODEL_NAME,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/home/gleb/.cache/huggingface/hub/models--unsloth--Qwen2.5-7B-Instruct/.no_exist/f8f9da84f4cb89d2e749d6eef5b87e68255a8e9e/chat_template.jinja'\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "response_template = \"<|im_start|>assistant\\n\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train,\n",
    "    eval_dataset = valid,\n",
    "    dataset_text_field = \"prompt_context\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = collator,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 16,\n",
    "        gradient_accumulation_steps = 2,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 3, # Set this for 1 full training run.\n",
    "        # eval_strategy=\"epoch\",\n",
    "        eval_steps=50,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 100,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 81,234 | Num Epochs = 3\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 2\n",
      "\\        /    Total batch size = 32 | Total steps = 7,617\n",
      " \"-____-\"     Number of trainable parameters = 40,370,176\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='7617' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  52/7617 16:23 < 41:20:42, 0.05 it/s, Epoch 0.02/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:157\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m<string>:382\u001b[0m, in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
      "File \u001b[0;32m<string>:64\u001b[0m, in \u001b[0;36m_unsloth_training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n",
      "File \u001b[0;32m/home/harddisk/projects/legal_ml/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:2248\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2248\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/harddisk/projects/legal_ml/.venv/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/harddisk/projects/legal_ml/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/harddisk/projects/legal_ml/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
