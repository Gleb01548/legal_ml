{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"src\" not in os.listdir():\n",
    "    os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "\n",
    "MODEL_NAME = \"unsloth/Qwen2.5-7B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"./data/interim/data_param_tunning/data_prompts.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>points</th>\n",
       "      <th>cat</th>\n",
       "      <th>prompt_dense_query</th>\n",
       "      <th>len_dense_query</th>\n",
       "      <th>prompt_dense_query_rerank</th>\n",
       "      <th>len_dense_query_rerank</th>\n",
       "      <th>prompt_dense_sparse_query</th>\n",
       "      <th>len_dense_sparse_query</th>\n",
       "      <th>prompt_dense_sparse_query_rerank</th>\n",
       "      <th>len_dense_sparse_query_rerank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12024168</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...</td>\n",
       "      <td>517</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...</td>\n",
       "      <td>488</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...</td>\n",
       "      <td>953</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...</td>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>854337</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...</td>\n",
       "      <td>1347</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...</td>\n",
       "      <td>1166</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...</td>\n",
       "      <td>893</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4748322</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...</td>\n",
       "      <td>1299</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...</td>\n",
       "      <td>1448</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...</td>\n",
       "      <td>1596</td>\n",
       "      <td>&lt;|im_start|&gt;system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...</td>\n",
       "      <td>1627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    points    cat  \\\n",
       "0           0  12024168  train   \n",
       "1           1    854337  train   \n",
       "2           2   4748322  train   \n",
       "\n",
       "                                  prompt_dense_query  len_dense_query  \\\n",
       "0  <|im_start|>system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...              517   \n",
       "1  <|im_start|>system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...             1347   \n",
       "2  <|im_start|>system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...             1299   \n",
       "\n",
       "                           prompt_dense_query_rerank  len_dense_query_rerank  \\\n",
       "0  <|im_start|>system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...                     488   \n",
       "1  <|im_start|>system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...                    1166   \n",
       "2  <|im_start|>system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...                    1448   \n",
       "\n",
       "                           prompt_dense_sparse_query  len_dense_sparse_query  \\\n",
       "0  <|im_start|>system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...                     953   \n",
       "1  <|im_start|>system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...                     893   \n",
       "2  <|im_start|>system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...                    1596   \n",
       "\n",
       "                    prompt_dense_sparse_query_rerank  \\\n",
       "0  <|im_start|>system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...   \n",
       "1  <|im_start|>system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...   \n",
       "2  <|im_start|>system\\n–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å...   \n",
       "\n",
       "   len_dense_sparse_query_rerank  \n",
       "0                            968  \n",
       "1                           1023  \n",
       "2                           1627  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"prompt_dense_query_rerank\"\n",
    "\n",
    "train = Dataset.from_dict({\"text\": df.loc[df[\"cat\"] == \"train\", col].to_list()})\n",
    "valid = Dataset.from_dict({\"text\": df.loc[df[\"cat\"] == \"valid\", col].to_list()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.2.4: Fast Qwen2 patching. Transformers: 4.48.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090. Max memory: 23.542 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c42cc4758654e04b134fa4fbbf76e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.2.4 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=MODEL_NAME,\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,  # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,  # Supports any, but = 0 is optimized\n",
    "    bias=\"none\",  # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for very long context\n",
    "    random_state=3407,\n",
    "    use_rslora=False,  # We support rank stabilized LoRA\n",
    "    loftq_config=None,  # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "response_template = \"<|im_start|>assistant\\n\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_from_disk(\"./data/processed/100k_rows_qwen\")\n",
    "train = dataset[\"train\"]\n",
    "valid = dataset[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7441ee20084be5b0bbce0ed2616aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=64):   0%|          | 0/81234 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e9853724f948daa6fc209f538d7499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=64):   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=valid,\n",
    "    dataset_text_field=\"prompt_context\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    data_collator=collator,\n",
    "    dataset_num_proc=64,\n",
    "    packing=False,  # Can make training 5x faster for short sequences.\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=16,\n",
    "        gradient_accumulation_steps=2,\n",
    "        warmup_steps=5,\n",
    "        num_train_epochs=3,  # Set this for 1 full training run.\n",
    "        # eval_strategy=\"epoch\",\n",
    "        eval_steps=50,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=not is_bfloat16_supported(),\n",
    "        bf16=is_bfloat16_supported(),\n",
    "        logging_steps=100,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        output_dir=\"outputs\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "–¢—ã —é—Ä–∏—Å—Ç. –¢—ã –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–µ—à—å –ª—é–¥–µ–π –ø–æ —Ä–∞–∑–Ω—ã–º –ø—Ä–æ–±–ª–µ–º–∞–º, –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–π, —á—Ç–æ —Ç–µ–±–µ –ø–∏—à—É—Ç, –æ—Ç–≤–µ—Ç—å –Ω–∞ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –¥–∞–π –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é. –û—Ç–≤–µ—Ç –ø–∏—à–∏ —Ç–æ–ª—å–∫–æ –Ω–∞ –†–£–°–°–ö–û–ú —è–∑—ã–∫–µ!<|im_end|>\n",
      "<|im_start|>user\n",
      "–ö—Ç–æ –º–æ–∂–µ—Ç —Å–¥–µ–ª–∞—Ç—å —Ñ–æ—Ä–º—É P 13014?\n",
      "–°—Ä–æ—á–Ω–æ.<|im_end|>\n",
      "<|im_start|>system\n",
      "–ü–µ—Ä–µ–¥ —Ç–µ–º –∫–∞–∫ –¥–∞—Ç—å –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é –∏–∑—É—á–∏ –≤–æ–ø—Ä–æ—Å—ã –¥—Ä—É–≥–∏—Ö –ª—é–¥–µ–π –∏ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –Ω–∏—Ö –¥—Ä—É–≥–∏—Ö —é—Ä–∏—Å—Ç–æ–≤:\n",
      "–í–æ–ø—Ä–æ—Å –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞:\n",
      "    –ö–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å —Ñ 13014 –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Å–≤–µ–¥–µ–Ω–∏–π –≤ –ï–ì–†–Æ–õ –ø–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—É, –∑–∞—Ä–∞–Ω–µ–µ –±–ª–∞–≥–æ–¥–∞—Ä—é.\n",
      "    –û—Ç–≤–µ—Ç —é—Ä–∏—Å—Ç–∞:\n",
      "    –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ —Å—é–¥–∞, –æ–±—Ä–∞–∑—Ü—ã –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è\n",
      "    –í–æ–ø—Ä–æ—Å –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞:\n",
      "    –ì–¥–µ –º–æ–∂–Ω–æ –≤–∑—è—Ç—å –∫–æ–ø–∏—é —Ñ–æ—Ä–º—ã 4?\n",
      "    –û—Ç–≤–µ—Ç —é—Ä–∏—Å—Ç–∞:\n",
      "    –°–º–æ—Ç—Ä–∏—Ç–µ —Å—Å—ã–ª–∫—É:\n",
      "    –í–æ–ø—Ä–æ—Å –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞:\n",
      "    –ì–¥–µ –≤–∑—è—Ç—å —Ñ–æ—Ä–º—É —ç—Ç–æ–π —Å–ø—Ä–∞–≤–∫–∏.\n",
      "    –û—Ç–≤–µ—Ç —é—Ä–∏—Å—Ç–∞:\n",
      "    –£–≤–∞–∂–∞–µ–º–∞—è –¢–∞—Ç—å—è–Ω–∞ —É—Ç–æ—á–Ω–∏—Ç–µ –≤–æ–ø—Ä–æ—Å, –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ –æ –∫–∞–∫–æ–π —Å–ø—Ä–∞–≤–∫–µ –∏–¥–µ—Ç —Ä–µ—á—å.\n",
      "    <|im_end|>\n",
      "<|im_start|>assistant\n",
      "–ö–∞–∫–∏–µ —É –≤–∞—Å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏?<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train[\"prompt_context\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "888"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\n",
    "    \"\"\"\n",
    "<|im_start|>system\n",
    "–¢—ã —é—Ä–∏—Å—Ç. –¢—ã –∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–µ—à—å –ª—é–¥–µ–π –ø–æ —Ä–∞–∑–Ω—ã–º –ø—Ä–æ–±–ª–µ–º–∞–º, –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–π, —á—Ç–æ —Ç–µ–±–µ –ø–∏—à—É—Ç, –æ—Ç–≤–µ—Ç—å –Ω–∞ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏ –¥–∞–π –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é. –û—Ç–≤–µ—Ç –ø–∏—à–∏ —Ç–æ–ª—å–∫–æ –Ω–∞ –†–£–°–°–ö–û–ú —è–∑—ã–∫–µ!<|im_end|>\n",
    "<|im_start|>user\n",
    "–ö—Ç–æ –º–æ–∂–µ—Ç —Å–¥–µ–ª–∞—Ç—å —Ñ–æ—Ä–º—É P 13014?\n",
    "–°—Ä–æ—á–Ω–æ.<|im_end|>\n",
    "<|im_start|>system\n",
    "–ü–µ—Ä–µ–¥ —Ç–µ–º –∫–∞–∫ –¥–∞—Ç—å –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é –∏–∑—É—á–∏ –≤–æ–ø—Ä–æ—Å—ã –¥—Ä—É–≥–∏—Ö –ª—é–¥–µ–π –∏ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –Ω–∏—Ö –¥—Ä—É–≥–∏—Ö —é—Ä–∏—Å—Ç–æ–≤:\n",
    "–í–æ–ø—Ä–æ—Å –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞:\n",
    "    –ö–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å —Ñ 13014 –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Å–≤–µ–¥–µ–Ω–∏–π –≤ –ï–ì–†–Æ–õ –ø–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—É, –∑–∞—Ä–∞–Ω–µ–µ –±–ª–∞–≥–æ–¥–∞—Ä—é.\n",
    "    –û—Ç–≤–µ—Ç —é—Ä–∏—Å—Ç–∞:\n",
    "    –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ —Å—é–¥–∞, –æ–±—Ä–∞–∑—Ü—ã –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è\n",
    "    –í–æ–ø—Ä–æ—Å –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞:\n",
    "    –ì–¥–µ –º–æ–∂–Ω–æ –≤–∑—è—Ç—å –∫–æ–ø–∏—é —Ñ–æ—Ä–º—ã 4?\n",
    "    –û—Ç–≤–µ—Ç —é—Ä–∏—Å—Ç–∞:\n",
    "    –°–º–æ—Ç—Ä–∏—Ç–µ —Å—Å—ã–ª–∫—É:\n",
    "    –í–æ–ø—Ä–æ—Å –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞:\n",
    "    –ì–¥–µ –≤–∑—è—Ç—å —Ñ–æ—Ä–º—É —ç—Ç–æ–π —Å–ø—Ä–∞–≤–∫–∏.\n",
    "    –û—Ç–≤–µ—Ç —é—Ä–∏—Å—Ç–∞:\n",
    "    –£–≤–∞–∂–∞–µ–º–∞—è –¢–∞—Ç—å—è–Ω–∞ —É—Ç–æ—á–Ω–∏—Ç–µ –≤–æ–ø—Ä–æ—Å, –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ –æ –∫–∞–∫–æ–π —Å–ø—Ä–∞–≤–∫–µ –∏–¥–µ—Ç —Ä–µ—á—å.\n",
    "    <|im_end|>\n",
    "<|im_start|>assistant\n",
    "–ö–∞–∫–∏–µ —É –≤–∞—Å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏?<|im_end|>\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "–¢—ã —é—Ä–∏—Å—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–æ—Å—Å–∏–π—Å–∫–æ–º—É –ø—Ä–∞–≤—É, —Ç–≤–æ—è –∑–∞–¥–∞—á–∞ –ø–æ–º–æ–≥–∞—Ç—å –ª—é–¥—è–º. –ò–∑—É—á–∏ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏–∑—É—á–∏ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –∑–∞—Ç–µ–º —Ç–µ–±–µ –≤–æ–ø—Ä–æ—Å—ã –¥—Ä—É–≥–∏—Ö –≥—Ä–∞–∂–¥–∞–Ω –∏ –æ—Ç–≤–µ—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –¥–∞–≤–∞–ª–∏ –Ω–∞ –Ω–∏—Ö –¥—Ä—É–≥–∏–µ —é—Ä–∏—Å—Ç—ã. –ù–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞. –û—Ç–≤–µ—Ç –ø–∏—à–∏ —Ç–æ–ª—å–∫–æ –Ω–∞ –†–£–°–°–ö–û–ú —è–∑—ã–∫–µ!<|im_end|>\n",
      "<|im_start|>user\n",
      "–£ –º–µ–Ω—è –ø—Ä–æ—Å—Ä–æ—á–∫–∞  –≤ 3 —Ç—ã—Å—è—á–∏ —Ä—É–±–ª–µ–π –≤ –º—Ñ–æ, –Ω–µ—Ç –¥–µ–Ω–µ–≥ –∑–∞–ø–ª–∞—Ç–∏—Ç—å —Ç–∞–∫ –∫–∞–∫ —Å–∏–∂—É –≤—Ä–µ–º–µ–Ω–Ω–æ –±–µ–∑ —Ä–∞–±–æ—Ç—ã, —á—Ç–æ –±—É–¥–µ—Ç –µ—Å–ª–∏ –Ω–µ –∑–∞–ø–ª–∞—á—É. –ë—Ä–∞–ª –∑–∞–π–º –æ–Ω–ª–∞–π–Ω –±–µ–∑ –ø–æ—Å–µ—â–µ–Ω–∏—è –æ—Ñ–∏—Å–∞.<|im_end|>\n",
      "<|im_start|>system\n",
      "–ü—Ä–µ–∂–¥–µ —á–µ–º –¥–∞—Ç—å –æ—Ç–≤–µ—Ç –∏–∑—É—á–∏ –≤–æ–ø—Ä–æ—Å—ã –¥—Ä—É–≥–∏—Ö –≥—Ä–∞–∂–¥–∞–Ω –∏ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –Ω–∏—Ö —é—Ä–∏—Å—Ç–æ–≤:\n",
      "\n",
      "–í–æ–ø—Ä–æ—Å –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞:\n",
      "–£ –º–µ–Ω—è –ø—Ä–æ—Å—Ä–æ—á–∫–∞  –ø–æ –ø–ª–∞—Ç–µ–∂–∞–º –≤ –º—Ñ–æ, —á—Ç–æ –¥–µ–ª–∞—Ç—å –¥–µ–Ω–µ–≥ –Ω–µ—Ç –ø–æ—Ç–µ—Ä—è–ª —Ä–∞–±–æ—Ç—É –∑–≤–æ–Ω–∫–∏ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ. –°–ø–∞—Å–∏–±–æ.\n",
      "\n",
      "–û—Ç–≤–µ—Ç —é—Ä–∏—Å—Ç–∞:\n",
      "–í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–æ–≥–æ, —á–µ–≥–æ —Ö–æ—Ç–∏—Ç–µ –¥–æ–±–∏—Ç—å—Å—è.\n",
      "\n",
      "–í–æ–ø—Ä–æ—Å –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞:\n",
      "–ë—Ä–∞–ª–∞ –∑–∞–π–º –ú–§–û —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç  –º–µ—Å—è—Ü –æ–ø–ª–∞—Ç–∏–ª–∞. –°–µ–π—á–∞—Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –æ–ø–ª–∞—Ç–∏—Ç—å –Ω–µ—Ç –ø—Ä–æ—Å—Ä–æ—á–∫–∞ —Ç—Ä–∏ –º–µ—Å—è—Ü–∞. –ü–æ–¥—Å–∫–∞–∂–∏—Ç–µ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ —á–µ–º –º–Ω–µ —ç—Ç–æ –≥—Ä–æ–∑–∏—Ç. –û–Ω–∏ –º–Ω–µ –ø–æ–∫–∞ –Ω–µ –∑–≤–æ–Ω—è—Ç.\n",
      "\n",
      "–û—Ç–≤–µ—Ç —é—Ä–∏—Å—Ç–∞:\n",
      "–ú–§–û –≤–ø—Ä–∞–≤–µ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –≤ —Å—É–¥ –∑–∞ –≤–∑—ã—Å–∫–∞–Ω–∏–µ–º –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç–∏ —Å –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º–∏.\n",
      "\n",
      "–í–æ–ø—Ä–æ—Å –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞:\n",
      "–î–æ–±—Ä–æ–µ —É—Ç—Ä–æ —è –≤–∑—è–ª –∑–∞–π–º –≤ –ú–§–û —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç —Å–µ–π—á–∞—Å —É –º–µ–Ω—è –Ω–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –æ–ø–ª–∞—Ç–∏—Ç—å —á—Ç–æ –º–Ω–µ –¥–µ–ª–∞—Ç—å, —á–µ–º —ç—Ç–æ –º–Ω–µ –º–æ–∂–µ—Ç –≥—Ä–æ–∑–∏—Ç—å?\n",
      "\n",
      "–û—Ç–≤–µ—Ç —é—Ä–∏—Å—Ç–∞:\n",
      "–î–æ–ª–≥ —Å –≤–∞—Å –≤–∑—ã—â—É—Ç —á–µ—Ä–µ–∑ —Å—É–¥ —Å –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º–∏ –∏ —à—Ç—Ä–∞—Ñ–∞–º–∏.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ.–ú–§–û –º–æ–∂–µ—Ç –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –≤ —Å—É–¥ –∏ —Ç—Ä–µ–±–æ–≤–∞—Ç—å –æ–ø–ª–∞—Ç—ã –¥–æ–ª–≥–∞ –∏ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤.–í —Å—É–¥–µ –í—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ—Å–∏—Ç—å —Å–Ω–∏–∑–∏—Ç—å –ø—Ä–æ—Ü–µ–Ω—Ç—ã. –ü–æ—Å–ª–µ –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è —Ä–µ—à–µ–Ω–∏—è —Å—É–¥–∞ –≤ –∑–∞–∫–æ–Ω–Ω—É—é —Å–∏–ª—É –º–æ–∂–µ—Ç–µ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –≤ —Å—É–¥ –≤—ã–Ω–µ—Å—à–∏–π —Ä–µ—à–µ–Ω–∏–µ –∏ –ø—Ä–æ—Å–∏—Ç—å –æ—Ç—Å—Ä–æ—á–∏—Ç—å –∏/–∏–ª–∏ —Ä–∞—Å—Å—Ä–æ—á–∏—Ç—å –æ–ø–ª–∞—Ç—É –¥–æ–ª–≥–∞.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train[\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 81,234 | Num Epochs = 3\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 2\n",
      "\\        /    Total batch size = 32 | Total steps = 7,617\n",
      " \"-____-\"     Number of trainable parameters = 40,370,176\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='7617' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   4/7617 00:45 < 48:28:35, 0.04 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:157\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m<string>:398\u001b[0m, in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
      "File \u001b[0;32m/home/harddisk/projects/legal_ml/.venv/lib/python3.12/site-packages/transformers/trainer.py:4525\u001b[0m, in \u001b[0;36mTrainer.floating_point_ops\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4512\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4513\u001b[0m \u001b[38;5;124;03mFor models that inherit from [`PreTrainedModel`], uses that method to compute the number of floating point\u001b[39;00m\n\u001b[1;32m   4514\u001b[0m \u001b[38;5;124;03moperations for every backward + forward pass. If using another model, either implement such a method in the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4522\u001b[0m \u001b[38;5;124;03m    `int`: The number of floating-point operations.\u001b[39;00m\n\u001b[1;32m   4523\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloating_point_ops\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloating_point_ops\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/home/harddisk/projects/legal_ml/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1212\u001b[0m, in \u001b[0;36mModuleUtilsMixin.floating_point_ops\u001b[0;34m(self, input_dict, exclude_embeddings)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfloating_point_ops\u001b[39m(\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;28mself\u001b[39m, input_dict: Dict[\u001b[38;5;28mstr\u001b[39m, Union[torch\u001b[38;5;241m.\u001b[39mTensor, Any]], exclude_embeddings: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m    Get number of (optionally, non-embeddings) floating-point operations for the forward and backward passes of a\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;124;03m    batch with this transformer model. Default approximation neglects the quadratic dependency on the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;124;03m        `int`: The number of floating-point operations.\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m6\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_tokens(input_dict) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_embeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/harddisk/projects/legal_ml/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1130\u001b[0m, in \u001b[0;36mModuleUtilsMixin.num_parameters\u001b[0;34m(self, only_trainable, exclude_embeddings)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;124;03mGet number of (optionally, trainable or non-embeddings) parameters in the module.\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;124;03m    `int`: The number of parameters.\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exclude_embeddings:\n\u001b[1;32m   1129\u001b[0m     embedding_param_names \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m-> 1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1132\u001b[0m     total_parameters \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1133\u001b[0m         parameter \u001b[38;5;28;01mfor\u001b[39;00m name, parameter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_parameters() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m embedding_param_names\n\u001b[1;32m   1134\u001b[0m     ]\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/home/harddisk/projects/legal_ml/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2820\u001b[0m, in \u001b[0;36mModule.named_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2818\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2819\u001b[0m submodule_prefix \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m name\n\u001b[0;32m-> 2820\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_modules(\n\u001b[1;32m   2821\u001b[0m     memo, submodule_prefix, remove_duplicate\n\u001b[1;32m   2822\u001b[0m )\n",
      "File \u001b[0;32m/home/harddisk/projects/legal_ml/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2820\u001b[0m, in \u001b[0;36mModule.named_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2818\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2819\u001b[0m submodule_prefix \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m name\n\u001b[0;32m-> 2820\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_modules(\n\u001b[1;32m   2821\u001b[0m     memo, submodule_prefix, remove_duplicate\n\u001b[1;32m   2822\u001b[0m )\n",
      "    \u001b[0;31m[... skipping similar frames: Module.named_modules at line 2820 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m/home/harddisk/projects/legal_ml/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2820\u001b[0m, in \u001b[0;36mModule.named_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2818\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2819\u001b[0m submodule_prefix \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m name\n\u001b[0;32m-> 2820\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_modules(\n\u001b[1;32m   2821\u001b[0m     memo, submodule_prefix, remove_duplicate\n\u001b[1;32m   2822\u001b[0m )\n",
      "File \u001b[0;32m/home/harddisk/projects/legal_ml/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2775\u001b[0m, in \u001b[0;36mModule.named_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2772\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_modules():\n\u001b[1;32m   2773\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m module\n\u001b[0;32m-> 2775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnamed_modules\u001b[39m(\n\u001b[1;32m   2776\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2777\u001b[0m     memo: Optional[Set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2778\u001b[0m     prefix: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2779\u001b[0m     remove_duplicate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2780\u001b[0m ):\n\u001b[1;32m   2781\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return an iterator over all modules in the network, yielding both the name of the module as well as the module itself.\u001b[39;00m\n\u001b[1;32m   2782\u001b[0m \n\u001b[1;32m   2783\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2808\u001b[0m \n\u001b[1;32m   2809\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m memo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
